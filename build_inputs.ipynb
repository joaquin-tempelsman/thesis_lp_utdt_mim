{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.build_data_modules import *\n",
    "from utils.build_data_modules_old import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "clases: 3 \n",
      "años modelo: 1.6666666666666667 años \n",
      "meses vida max: 120 meses, 10 años\n",
      "ventas max por mes 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "version = '0.09'\n",
    "clases = 3\n",
    "periodos_modelo = 20  #1 año\n",
    "meses_max_animales = 12 * 10 # 10 años, impacta en reproductoras\n",
    "ventas_max_por_mes = 100\n",
    "\n",
    "#este valor se usa para tomar un stock inicial\n",
    "#y para pasar precios desde el periodo 0 a el final del modelo\n",
    "fecha_inicio = '30/06/2020'\n",
    "\n",
    "\n",
    "print(f'''\n",
    "clases: {clases} \n",
    "años modelo: {float(periodos_modelo / 12 )} años \n",
    "meses vida max: {meses_max_animales} meses, {int(meses_max_animales/12)} años\n",
    "ventas max por mes {ventas_max_por_mes}\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file_parametros = 'parametros.dat'\n",
    "\n",
    "if os.path.exists(path_to_file_parametros):\n",
    "    os.remove(path_to_file_parametros)\n",
    "\n",
    "write_line_to_file(path_to_file_parametros, 'parametros\\n')\n",
    "write_line_to_file(path_to_file_parametros, f'tiempo {periodos_modelo}\\n')\n",
    "write_line_to_file(path_to_file_parametros, f'semanas {meses_max_animales}\\n')\n",
    "write_line_to_file(path_to_file_parametros, f'{ventas_max_por_mes}\\n')\n",
    "\n",
    "# Extra - semanas que son agosto\n",
    "# nacimientos solo en agosto\n",
    "path_to_file_agosto = 'agosto_si.dat'\n",
    "path_to_file_not_agosto = 'agosto_no.dat'\n",
    "path_to_file_momentos_venta = 'momentos_venta_no_posible_c1_c2.dat'\n",
    "path_to_file_ventas_max_por_mes = 'ventas_max_por_mes.dat'\n",
    "\n",
    "if os.path.exists(path_to_file_agosto):\n",
    "    os.remove(path_to_file_agosto)\n",
    "\n",
    "if os.path.exists(path_to_file_not_agosto):\n",
    "    os.remove(path_to_file_not_agosto)\n",
    "\n",
    "\n",
    "num = 8\n",
    "counter = 0\n",
    "for semanas in range(periodos_modelo + 1):\n",
    "\n",
    "    if counter != num:\n",
    "        write_line_to_file(path_to_file_not_agosto, f'{counter}\\n')\n",
    "    \n",
    "    else:\n",
    "        write_line_to_file(path_to_file_agosto, f'{counter}\\n')\n",
    "        num = num +  8\n",
    "    \n",
    "    counter = counter + 1\n",
    "\n",
    "if os.path.exists(path_to_file_momentos_venta):\n",
    "    os.remove(path_to_file_momentos_venta)\n",
    "\n",
    "venta_destete = [6,7,8]\n",
    "venta_novillo_vaquillona = [16,17,18]\n",
    "venta_pesados = [30,31,32,33,34,35,36]\n",
    "venta_all = venta_destete + venta_novillo_vaquillona + venta_pesados\n",
    "\n",
    "for mes in [x for x in range(0,meses_max_animales) if x not in venta_all]:\n",
    "    write_line_to_file(path_to_file_momentos_venta, f'{mes}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_costos = []\n",
    "\n",
    "#path_to_file_costos = 'modelos/mod_{version}/costos.dat'.format(version=version)\n",
    "path_to_file_costos = 'costos.dat'\n",
    "\n",
    "if os.path.exists(path_to_file_costos):\n",
    "    os.remove(path_to_file_costos)\n",
    "\n",
    "for periodo, edad_animal, clase in itertools.product(range(1,periodos_modelo+1), range(-1,meses_max_animales + 1), range(1,clases+1)):\n",
    "\n",
    "    # a mayor edad del animal, el impacto es positivo pero decreciente en funcion del tiempo\n",
    "    # a medida que avanzan los periodos, es menos costoso mantener a un animal\n",
    "    costo = 1 + edad_animal * 0.25\n",
    "    \n",
    "    if math.isinf(costo) | math.isnan(costo) :\n",
    "        costo = 1\n",
    "    #else:\n",
    "    if clase == 3:\n",
    "        costo = 0\n",
    "\n",
    "    valores = [periodo,edad_animal,clase,costo,'\\n']\n",
    "    line = '\\t'.join(str(x) for x in valores)\n",
    "    write_line_to_file(path_to_file_costos, line)\n",
    "\n",
    "    #plot costos\n",
    "    collect_costos.append({'periodo': periodo , 'costo': costo, 'edad':edad_animal, 'clase':clase})\n",
    "\n",
    "df_costos = pd.DataFrame(collect_costos)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot costos pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap_c1 = df_costos.loc[df_costos.clase == 1].pivot(index='edad', columns='periodo', values=['costo'])\n",
    "# heatmap_c2 = df_costos.loc[df_costos.clase == 2].pivot(index='edad', columns='periodo', values=['costo'])\n",
    "# heatmap_c3 = df_costos.loc[df_costos.clase == 3].pivot(index='edad', columns='periodo', values=['costo'])\n",
    "\n",
    "\n",
    "# #df = px.data.medals_wide(indexed=True)\n",
    "# fig = px.imshow(heatmap_c1)\n",
    "# fig.show()\n",
    "\n",
    "# fig = px.imshow(heatmap_c2)\n",
    "# fig.show()\n",
    "\n",
    "# fig = px.imshow(heatmap_c3)\n",
    "# fig.show()\n",
    "\n",
    "# df_costos_b = df_costos.loc[df_costos['edad'] == 100]\n",
    "# fig = px.line(df_costos_b, x=\"periodo\", y=\"costo\", color='clase')\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECIOS Y STOCK INICIAL V1 reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.build_data_modules import *\n",
    "\n",
    "FECHA_PARTE_DIARIO = '6/26/2020'\n",
    "FECHA_INICIO_SCRAPPING = '30/06/2020'\n",
    "\n",
    "precio_prom =  {\n",
    "              'peso_prom_destete': 164, \n",
    "              'peso_prom_vaquillonas': 314,\n",
    "              'peso_prom_novillitos': 367,\n",
    "              'peso_prom_vaquillonas_pesados': 433,\n",
    "              'peso_prom_novillos_pesados': 438\n",
    "       }\n",
    "\n",
    "df_precios = get_precios_scrapped(fecha_inicio = FECHA_INICIO_SCRAPPING,\n",
    "                    input='data/scrapping_df3 - scrapping_df3.csv')\n",
    "\n",
    "#plot_precios(df_precios)\n",
    "\n",
    "a = precios_scrapped_to_dat(df_precios,\n",
    "                        periodos_modelo = periodos_modelo,\n",
    "                        clases=clases,\n",
    "                        meses_max_animales = meses_max_animales,\n",
    "                        peso_prom_dict =precio_prom,\n",
    "                        path_to_file_precios= 'precios.dat',\n",
    "                        fecha_inicio = '30/06/2020'\n",
    ")\n",
    "\n",
    "\n",
    "get_stock_inicial_from_parte_diario(FECHA_PARTE_DIARIO,\n",
    "                                        clases,\n",
    "                                        meses_max_animales,\n",
    "                                        parte_diario_path='data/datos experimento tesis  - parte_diario completo.csv',\n",
    "                                        output='stock_inicial.dat'\n",
    "                                        )\n",
    "\n",
    "df_precios.to_csv('precios.csv')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>novillos_exp_joven_avg</th>\n",
       "      <th>novillos_regular_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/06/2022</td>\n",
       "      <td>293</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>285</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/07/2022</td>\n",
       "      <td>290</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/07/2022</td>\n",
       "      <td>302</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/08/2022</td>\n",
       "      <td>305</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/08/2022</td>\n",
       "      <td>310</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/09/2022</td>\n",
       "      <td>300</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30/09/2022</td>\n",
       "      <td>293</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/10/2022</td>\n",
       "      <td>280</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/10/2022</td>\n",
       "      <td>280</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/11/2022</td>\n",
       "      <td>290</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30/11/2022</td>\n",
       "      <td>300</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/12/2022</td>\n",
       "      <td>315</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>315</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha novillos_exp_joven_avg novillos_regular_avg\n",
       "0  16/06/2022                    293                  255\n",
       "0  30/06/2022                    285                  260\n",
       "0  15/07/2022                    290                  255\n",
       "0  31/07/2022                    302                  272\n",
       "0  15/08/2022                    305                  270\n",
       "0  31/08/2022                    310                  270\n",
       "0  15/09/2022                    300                  270\n",
       "0  30/09/2022                    293                  260\n",
       "0  15/10/2022                    280                  247\n",
       "0  31/10/2022                    280                  254\n",
       "0  15/11/2022                    290                  260\n",
       "0  30/11/2022                    300                  260\n",
       "0  15/12/2022                    315                  265\n",
       "0  01/01/2023                    315                  280"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect = pd.DataFrame()\n",
    "with open('precios_missing_16062022_150123.txt', 'r') as f:\n",
    "    capture_lines = False\n",
    "    for line in f:\n",
    "        line = line.strip()  # Remove leading/trailing whitespace\n",
    "        if line == \"Fecha Inicial\":\n",
    "            capture_lines = True\n",
    "            count = 0\n",
    "            continue  # Start reading the next line\n",
    "        if capture_lines:\n",
    "            if count < 50:  # Capture only the next 50 lines\n",
    "                # Check if the line meets the conditions\n",
    "\n",
    "                if count == 0:\n",
    "                    fecha = line\n",
    "\n",
    "                if 'NOVILLOS Esp.Joven' in line:\n",
    "                    novillos_exp_joven_avg = int(line.split(' ')[8].split(',')[0])\n",
    "                \n",
    "                if 'NOVILLOS Regular h 430' in line:\n",
    "                    novillos_regular_avg = int(line.split(' ')[8].split(',')[0])\n",
    "                \n",
    "                count += 1\n",
    "            else:\n",
    "                serie = pd.Series([fecha, novillos_exp_joven_avg, novillos_regular_avg], index=['fecha', 'novillos_exp_joven_avg', 'novillos_regular_avg'])\n",
    "                #print(fecha, novillos_exp_joven_avg, novillos_regular_avg)\n",
    "                df_collect = pd.concat([df_collect, serie.to_frame().T])\n",
    "                capture_lines = False\n",
    "\n",
    "df_collect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precios y stock inicial V0 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stock_inicial_v0(output_path= 'stock_inicial.dat',\n",
    "#                         clases= clases,\n",
    "#                         meses_max_animales= meses_max_animales,\n",
    "#                         edad_animal= meses_max_animales)\n",
    "\n",
    "# get_precios_v0(output_path = 'precios.dat',\n",
    "#                 clases= clases,\n",
    "#                 meses_max_animales= meses_max_animales,\n",
    "#                 edad_animal= meses_max_animales,\n",
    "#                 periodos_modelo= periodos_modelo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventas de parte diario a pesos usando precios scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: diferencia de precio mayor a 15 dias for 2007-01-06 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2007-12-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2008-01-05 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2008-12-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2009-01-03 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2009-12-26 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2010-12-25 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2011-07-02 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2011-09-10 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2011-10-01 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2011-12-24 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-04-07 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-05-19 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-06-30 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-07-07 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-07-14 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-07-21 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-07-28 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-08-04 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-08-11 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-08-18 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-08-25 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-09-01 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-09-11 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-09-15 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-09-22 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-09-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-10-06 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-10-13 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-10-20 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-10-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-11-03 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-11-10 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-11-24 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-12-22 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2012-12-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-01-05 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-01-12 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-01-19 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-01-26 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-02-02 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-02-09 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-02-16 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-02-23 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-03-02 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-03-09 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-03-16 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-03-23 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-03-30 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-04-06 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-04-13 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-04-20 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-04-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-05-04 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-05-11 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-05-18 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-05-25 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-06-01 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-06-08 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-06-15 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-06-22 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-06-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-07-06 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-07-13 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-07-20 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-07-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-08-03 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-08-10 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-08-17 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-08-24 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-08-31 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-09-07 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-12-21 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2013-12-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2014-01-04 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2014-01-11 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-06-16 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-06-23 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-06-30 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-07-07 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-07-14 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-07-21 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-07-28 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-08-04 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-08-11 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-08-18 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-08-25 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-09-01 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-09-08 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-09-15 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-09-22 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-09-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-10-06 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-10-13 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-10-20 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-10-27 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-11-03 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-11-10 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-11-17 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-11-24 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-12-01 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-12-08 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-12-15 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-12-22 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2022-12-29 00:00:00\n",
      "WARNING: diferencia de precio mayor a 15 dias for 2023-01-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df_ventas = get_ventas_inicial_from_parte_diario(parte_diario_path='data/datos experimento tesis  - parte_diario completo.csv')\n",
    "\n",
    "\n",
    "# iteramos por cada venta en el parte diario y la pesificamos usando el precio mas cercano\n",
    "# en el dataset de precios scrappeados. Obtenemos una nueva columna en df_ventas con la venta en pesos para ese dia\n",
    "\n",
    "for index, row in df_ventas.iterrows():\n",
    "    precios = get_precios_del_periodo(row.FECHA, df_precios)\n",
    "    sub_tot_VAQUILLONAS270 = row['VAQUILLONAS270'] * precios['VAQUILLONAS270']\n",
    "    sub_tot_NOVILLITOS391 = row['NOVILLITOS391'] * precios['NOVILLITOS391']\n",
    "    sub_tot_NOVILLITOS300 = row['NOVILLITOS300'] * precios['NOVILLITOS300']\n",
    "    #sub_tot_VACAS = row['VACAS'] * precios['VACAS']\n",
    "    #sub_tot_TOROS = row['TOROS'] * precios['TOROS']\n",
    "    #sub_tot_TERNEROS_DESTETE = row['TERNEROS_DESTETE'] * precios['TERNEROS_DESTETE']\n",
    "    #sub_tot_TERNERAS_DESTETE = row['TERNERAS_DESTETE'] * precios['TERNERAS_DESTETE']\n",
    "    VENTA_TOT_DIA = (sub_tot_VAQUILLONAS270 + \n",
    "        sub_tot_NOVILLITOS391 +\n",
    "        sub_tot_NOVILLITOS300 \n",
    "    #    sub_tot_VACAS +\n",
    "    #    sub_tot_TOROS +\n",
    "    #    sub_tot_TERNEROS_DESTETE +\n",
    "    #    sub_tot_TERNERAS_DESTETE\n",
    "    )\n",
    "    df_ventas.loc[index, 'VENTA_PESOS'] = VENTA_TOT_DIA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4efcaedce4fb114d846e2d0242e28239acaf891ca69a5ad0204dd83873777535"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
